{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a345bf3-d1e2-4d9f-98a5-0826aead27cd",
   "metadata": {},
   "source": [
    "# <font color = orange> Section Header --> <font color = teal> RobertaXL + LongFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f94e26-11f2-4e54-8003-6ed514a61a47",
   "metadata": {},
   "source": [
    "### <font color = blue> REDO: HF Inference: RobertaXL and LongFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633bac53-7898-458f-bcdc-b367f6f08c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv.main import load_dotenv\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000f4c4d-44f5-4087-a0dc-ecd3c10383ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60d3caa-0d6b-47ab-b5c6-87f86328f13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/20231116_MediQA/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# Set to display full (non-truncated) dataframe information\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afecaab7-0927-4153-a8ed-5e9febcb60eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Set your Hugging Face API token as an environment variable\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "# Save the token using HfFolder\n",
    "HfFolder.save_token(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda79c8d-5326-4fab-a5f2-103905eb0e9d",
   "metadata": {},
   "source": [
    "# <font color = green> START HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c5411-8ad4-4789-b10c-8b572fc5f5d1",
   "metadata": {},
   "source": [
    "## <font color = orange> Roberta-Base HF Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27108ecb-b052-48b0-b5dc-6223a75260a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the test dataset\n",
    "test_data_path = '/home/gaurav_narasimhan/03.gn_projects/03.MediQA_2023/11.Source_Data/MTS-Dialog-TestSet-1-MEDIQA-Chat-2023.csv'\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ba5d87-47c7-4928-96b8-67556193afb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b54f65-c2f5-4679-801d-85ae6a2f4af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_dict = {\n",
    "#     'GENHX': 0,\n",
    "#     'MEDICATIONS': 1,\n",
    "#     'CC': 2,\n",
    "#     'PASTMEDICALHX': 3,\n",
    "#     'ALLERGY': 4,\n",
    "#     'FAM/SOCHX': 5,\n",
    "#     'PASTSURGICAL': 6,\n",
    "#     'OTHER_HISTORY': 7,\n",
    "#     'ASSESSMENT': 8,\n",
    "#     'ROS': 9,\n",
    "#     'DISPOSITION': 10,\n",
    "#     'EXAM': 11,\n",
    "#     'PLAN': 12,\n",
    "#     'DIAGNOSIS': 13,\n",
    "#     'EDCOURSE': 14,\n",
    "#     'IMMUNIZATIONS': 15,\n",
    "#     'LABS': 16,\n",
    "#     'IMAGING': 17,\n",
    "#     'PROCEDURES': 18,\n",
    "#     'GYNHX': 19\n",
    "# }\n",
    "\n",
    "label_dict = {\n",
    "    'ALLERGY': 0,\n",
    "    'ASSESSMENT': 1,\n",
    "    'CC': 2,\n",
    "    'DIAGNOSIS': 3,\n",
    "    'DISPOSITION': 4,\n",
    "    'EDCOURSE': 5,\n",
    "    'EXAM': 6,\n",
    "    'FAM/SOCHX': 7,\n",
    "    'GENHX': 8,\n",
    "    'GYNHX': 9,\n",
    "    'IMAGING': 10,\n",
    "    'IMMUNIZATIONS': 11,\n",
    "    'LABS': 12,\n",
    "    'MEDICATIONS': 13,\n",
    "    'OTHER_HISTORY': 14,\n",
    "    'PASTMEDICALHX': 15,\n",
    "    'PASTSURGICAL': 16,\n",
    "    'PLAN': 17,\n",
    "    'PROCEDURES': 18,\n",
    "    'ROS': 19\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ea023-4607-42ca-8373-d41b3811c236",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1c8915-e1a3-42e4-937f-b672c04bb646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the dialogues\n",
    "encodings = tokenizer(\n",
    "    test_data['dialogue'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,  # Adjust max_length if needed\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Load your pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"zibajoon/20231127_Roberta_10ep_NewLabels_Classn_79\",\n",
    "    num_labels=20  # Adjust num_labels if needed\n",
    ")\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a0fcf5-4eb4-471a-8c2d-db8c1e22e19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to predict without using label dictionary\n",
    "def predict_raw_output(model, encodings):\n",
    "    predicted_indices = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(encodings['input_ids'].size(0)):\n",
    "            inputs = {key: val[i].unsqueeze(0) for key, val in encodings.items()}\n",
    "            outputs = model(**inputs)\n",
    "            pred_label_idx = torch.argmax(outputs.logits, dim=1).item()\n",
    "            predicted_indices.append(pred_label_idx)\n",
    "            \n",
    "            # Print debugging information\n",
    "            # print(f\"Index: {i}, Predicted Label Index: {pred_label_idx}\")\n",
    "\n",
    "    return predicted_indices\n",
    "\n",
    "# Perform inference to get raw output\n",
    "predicted_indices = predict_raw_output(model, encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a69b08-c8d1-4d63-97c2-17d571cded4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Invert the label_dict to map indices to labels\n",
    "index_to_label = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# Map predicted label indices to label names\n",
    "predicted_labels = [index_to_label.get(idx, \"Unknown Label\") for idx in predicted_indices]\n",
    "\n",
    "# Extract the actual labels from the test data\n",
    "actual_labels = test_data['section_header'].tolist()\n",
    "\n",
    "# # Compare predicted labels with actual labels\n",
    "# for i, (pred, actual) in enumerate(zip(predicted_labels, actual_labels)):\n",
    "#     print(f\"Index: {i}, Predicted Label: {pred}, Actual Label: {actual}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f49ba-6800-4c4e-bbd6-964d2bed28bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d8d63-2804-477a-8b17-03bac5718c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20231119_MediQA",
   "language": "python",
   "name": "20231119_mediqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
